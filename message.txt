from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Tuple, Dict, Any
from picamera2 import Picamera2
from ultralytics import YOLO
import cv2
import time
import numpy as np

# --- FastAPI App ---
app = FastAPI(title="Smart Exercise & Posture Recognition - Human Detection API")

# --- Detection Configuration ---
DURATION = 5
FRAME_SKIP = 5
GRID_ROWS, GRID_COLS = 3, 3

appliance_map = {
    (0, 0): ["Light 1 (Back Left)"], (0, 1): ["Light 2 (Back Center)"], (0, 2): ["Light 3 (Back Right)"],
    (1, 0): ["Fan 1 (Mid Left)"],    (1, 1): ["Projector"],             (1, 2): ["Fan 2 (Mid Right)"],
    (2, 0): ["Light 4 (Front Left)"], (2, 1): ["Light 5 (Front Center)"], (2, 2): ["Light 6 (Front Right)"]
}

# --- Load YOLO Model once at startup ---
print("[INFO] Loading YOLOv8 model...")
model = YOLO("yolov8n.pt")

# --- Response Schema ---
class CommandResult(BaseModel):
    zone: Tuple[int, int]
    status: str
    appliances: List[str]

class DetectionResponse(BaseModel):
    human_detected: bool
    occupied_zones: List[Tuple[int, int]]
    commands: List[CommandResult]

# --- Utility: Run Detection ---
def run_detection() -> DetectionResponse:
    print("[INFO] Initializing PiCamera2...")
    picam2 = Picamera2()
    picam2.preview_configuration.main.size = (640, 480)
    picam2.preview_configuration.main.format = "RGB888"
    picam2.configure("preview")
    picam2.start()

    start_time = time.time()
    frame_count = 0
    processed_frames = 0
    frames_with_humans = 0
    last_occupied_grids = set()

    print(f"[INFO] Running detection for {DURATION} seconds...")
    while (time.time() - start_time) < DURATION:
        frame = picam2.capture_array()
        h, w, _ = frame.shape
        cell_h, cell_w = h // GRID_ROWS, w // GRID_COLS
        frame_count += 1

        if frame_count % FRAME_SKIP == 0:
            processed_frames += 1
            results = model(frame, classes=0, conf=0.5, verbose=False)
            current_frame_grids = set()

            for r in results:
                if len(r.boxes) > 0:
                    frames_with_humans += 1
                for box in r.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                    grid_col, grid_row = int(center_x // cell_w), int(center_y // cell_h)
                    if 0 <= grid_row < GRID_ROWS and 0 <= grid_col < GRID_COLS:
                        current_frame_grids.add((grid_row, grid_col))
            last_occupied_grids = current_frame_grids

    picam2.close()
    print("[INFO] Detection complete.")

    # --- Compute Human Detection Percentage ---
    detection_rate = (frames_with_humans / processed_frames * 100) if processed_frames > 0 else 0
    human_detected = detection_rate > 50.0  # âœ… True only if > 50%

    print(f"[INFO] Human detection rate: {detection_rate:.2f}%")
    print(f"[INFO] Human detected: {human_detected}")

    # --- Build Command Logic ---
    commands = []
    if human_detected:
        for r in range(GRID_ROWS):
            for c in range(GRID_COLS):
                zone = (r, c)
                appliances = appliance_map.get(zone, [])
                if not appliances:
                    continue
                if zone in last_occupied_grids:
                    commands.append(CommandResult(zone=zone, status="ON", appliances=appliances))
                else:
                    commands.append(CommandResult(zone=zone, status="OFF", appliances=appliances))
    else:
        for zone, appliances in appliance_map.items():
            commands.append(CommandResult(zone=zone, status="OFF", appliances=appliances))

    return DetectionResponse(
        human_detected=human_detected,
        occupied_zones=list(last_occupied_grids),
        commands=commands
    )

# --- API Endpoint ---
@app.post("/detect", response_model=DetectionResponse)
def detect_human():
    """
    Trigger a 5-second YOLOv8 human detection using PiCamera2.
    Returns detected zones and recommended appliance commands.
    """
    result = run_detection()
    return result

# --- Root Route ---
@app.get("/")
def root():
    return {"message": "Smart Exercise & Posture Recognition API is running!"}
