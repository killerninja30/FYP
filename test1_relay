from fastapi import FastAPI, Response
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Tuple
from picamera2 import Picamera2
from ultralytics import YOLO
import cv2
import time
import threading
import traceback
import RPi.GPIO as GPIO

# ==========================================================
# --- FASTAPI APP SETUP ---
# ==========================================================
app = FastAPI(title="Smart Exercise & Posture Recognition API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================================
# --- RELAY CONFIGURATION (GPIO PINS: 2, 3, 4, 17) ---
# ==========================================================
# Each grid row controls one relay channel
RELAY_PINS = {0: 2, 1: 3, 2: 4, "all_off": 17}  # BCM numbering
ALL_PINS = list(RELAY_PINS.values())

GPIO.setmode(GPIO.BCM)
for pin in ALL_PINS:
    GPIO.setup(pin, GPIO.OUT)
    GPIO.output(pin, GPIO.HIGH)  # relay OFF initially (active LOW)

def set_relay_state(row: int, state: str):
    """Turn ON/OFF relay corresponding to a row."""
    if row not in RELAY_PINS:
        return
    pin = RELAY_PINS[row]
    if state == "ON":
        GPIO.output(pin, GPIO.LOW)   # Active-LOW relay ON
    else:
        GPIO.output(pin, GPIO.HIGH)  # Relay OFF

def turn_off_all_relays():
    for pin in ALL_PINS:
        GPIO.output(pin, GPIO.HIGH)

# ==========================================================
# --- DETECTION SETTINGS ---
# ==========================================================
DURATION = 5
FRAME_SKIP = 5
GRID_ROWS, GRID_COLS = 3, 3

appliance_map = {
    (0,0):["Light 1 (Back Left)"], (0,1):["Light 2 (Back Center)"], (0,2):["Light 3 (Back Right)"],
    (1,0):["Fan 1 (Mid Left)"], (1,1):["Projector"], (1,2):["Fan 2 (Mid Right)"],
    (2,0):["Light 4 (Front Left)"], (2,1):["Light 5 (Front Center)"], (2,2):["Light 6 (Front Right)"]
}

print("[INFO] Loading YOLOv8 model...")
model = YOLO("yolov8n.pt")
print("[INFO] Model loaded successfully.")

# ==========================================================
# --- RESPONSE SCHEMAS ---
# ==========================================================
class CommandResult(BaseModel):
    zone: Tuple[int, int]
    status: str
    appliances: List[str]

class DetectionResponse(BaseModel):
    human_detected: bool
    occupied_zones: List[Tuple[int, int]]
    commands: List[CommandResult]

# ==========================================================
# --- CAMERA HANDLER ---
# ==========================================================
camera_lock = threading.Lock()
camera_instance = None

def get_camera():
    global camera_instance
    with camera_lock:
        if camera_instance is None:
            try:
                camera_instance = Picamera2()
                camera_instance.preview_configuration.main.size = (640, 480)
                camera_instance.preview_configuration.main.format = "RGB888"
                camera_instance.configure("preview")
                camera_instance.start()
            except Exception as e:
                print("[ERROR] Camera init failed:", e)
                camera_instance = None
        return camera_instance

# ==========================================================
# --- DETECTION FUNCTION ---
# ==========================================================
def run_detection() -> DetectionResponse:
    picam2 = get_camera()
    if picam2 is None:
        raise RuntimeError("Camera not available")

    start_time = time.time()
    frame_count = 0
    processed_frames = 0
    frames_with_humans = 0
    last_occupied_grids = set()

    while (time.time() - start_time) < DURATION:
        frame = picam2.capture_array()
        h, w, _ = frame.shape
        cell_h, cell_w = h // GRID_ROWS, w // GRID_COLS
        frame_count += 1

        if frame_count % FRAME_SKIP == 0:
            processed_frames += 1
            results = model(frame, classes=0, conf=0.25, verbose=False)
            current_frame_grids = set()

            for r in results:
                if len(r.boxes) > 0:
                    frames_with_humans += 1
                for box in r.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                    grid_col, grid_row = int(center_x // cell_w), int(center_y // cell_h)
                    if 0 <= grid_row < GRID_ROWS and 0 <= grid_col < GRID_COLS:
                        current_frame_grids.add((grid_row, grid_col))

            last_occupied_grids = current_frame_grids

    detection_rate = (frames_with_humans / processed_frames * 100) if processed_frames > 0 else 0
    human_detected = frames_with_humans > 0  # Loosened condition

    print(f"[DEBUG] Processed={processed_frames}, FramesWithHumans={frames_with_humans}, DetectionRate={detection_rate:.2f}%, HumanDetected={human_detected}")

    commands = []

    if human_detected:
        active_rows = set()
        for (r, c) in last_occupied_grids:
            active_rows.add(r)
            appliances = appliance_map.get((r, c), [])
            commands.append(CommandResult(zone=(r, c), status="ON", appliances=appliances))

        for row in range(GRID_ROWS):
            set_relay_state(row, "ON" if row in active_rows else "OFF")

    else:
        turn_off_all_relays()
        for zone, appliances in appliance_map.items():
            commands.append(CommandResult(zone=zone, status="OFF", appliances=appliances))

    return DetectionResponse(
        human_detected=human_detected,
        occupied_zones=list(last_occupied_grids),
        commands=commands
    )

# ==========================================================
# --- API ENDPOINTS ---
# ==========================================================
@app.post("/detect", response_model=DetectionResponse)
def detect_human():
    try:
        return run_detection()
    except Exception as e:
        print("[ERROR] Detection failed:", e)
        traceback.print_exc()
        turn_off_all_relays()
        return Response(
            content='{"error": "Internal server error during detection"}',
            media_type="application/json",
            status_code=500
        )

@app.on_event("shutdown")
def cleanup_gpio():
    print("[INFO] Cleaning up GPIO...")
    GPIO.cleanup()

# ==========================================================
# --- MJPEG PREVIEW (optional) ---
# ==========================================================
def mjpeg_stream_generator(duration_seconds=60):
    picam2 = get_camera()
    if picam2 is None:
        yield b"--frame\r\nContent-Type: text/plain\r\n\r\nCamera not available\r\n"
        return
    start = time.time()
    try:
        while True:
            frame = picam2.capture_array()
            bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            ret, jpeg = cv2.imencode(".jpg", bgr)
            if not ret:
                continue
            chunk = jpeg.tobytes()
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + chunk + b'\r\n')
            if duration_seconds and (time.time() - start) > duration_seconds:
                break
            time.sleep(0.05)
    except Exception as e:
        print("[ERROR] MJPEG stream failed:", e)

@app.get("/preview")
def preview():
    return StreamingResponse(
        mjpeg_stream_generator(duration_seconds=60),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

# ==========================================================
# --- SIMPLE UI ---
# ==========================================================
HTML_UI = """
<!doctype html>
<html>
<head><meta charset="utf-8"/><title>Smart Human Detection</title></head>
<body>
<h1>Smart Human Detection</h1>
<button id="startBtn">Start Detection</button>
<div id="status"></div>
<div id="preview" style="display:none;"><img src="/preview" width="640" height="480"/></div>
<pre id="result" style="display:none;"></pre>
<script>
const btn=document.getElementById('startBtn');
const status=document.getElementById('status');
const result=document.getElementById('result');
const preview=document.getElementById('preview');
btn.onclick=async()=>{
  preview.style.display='block'; result.style.display='none'; status.innerText='Running detection...';
  try{
    const res=await fetch('/detect',{method:'POST'});
    const text=await res.text(); let data;
    try{data=JSON.parse(text);}catch{throw new Error(text);}
    result.style.display='block'; result.innerText=JSON.stringify(data,null,2);
    status.innerText='Detection complete.';
  }catch(err){status.innerText='Error: '+err; result.style.display='block'; result.innerText=String(err);}
};
</script>
</body>
</html>
"""

@app.get("/ui", response_class=HTMLResponse)
def ui():
    return HTMLResponse(content=HTML_UI, status_code=200)

@app.get("/")
def root():
    return {"message": "Smart Exercise & Posture Recognition API with Relay Control is running!"}
